# Application of explanatory methods on CNN models for the diagnosis of Parkinson's disease
Code for the Final Degree Project  experimentation "Application of explanatory methods on CNN models for the diagnosis of Parkinson's disease".


## Introduction
This project is an extension of the article [An ordinal CNN approach for the assessment of neurological damage in Parkinson's disease patients](https://github.com/ayrna/ordinal-cnn-parkinsons), incorporating eXplainable Artificial Intelligence (XAI) techniques. The software adds the following functionalities:
- Application of explanatory techniques on the trained network models.
- Analysis of the heatmaps by evaluating the relevance assigned by XAI methods to brain regions that most influence the classification task.
- Generation of diagrams from the relevance analysis results.
- Comparative graphical representation of heatmaps obtained using explanatory methods, showing the axial, sagital, and coronal anatomical planes.


## Installation
The application has been developed and tested on **GNU/Linux** systems using **Python 3.9**. The `requirements.txt` file is included to facilitate the installation of all dependencies via the `pip` package manager by running the following command:
```bash
pip install  -r  requirements.txt
```
No additional installation steps are required. The provided code folder should be copied into the same directory as the original project.


## Configuration

### Configuration File `config.ini`
The application uses a `config.ini` configuration file that defines the paths to the directories and files that make up the project. The project structure is as follows:
-  `parkinson_reinasofia`: directory for input files.
    -  `parkinson_reinasofia/labels.csv`: file with the names of the images and their corresponding labels.
    -  `parkinson_reinasofia/mni`: input datasets.
-  `parkinson_signac`: directory for the project code and trained models.
-  `parkinson_xai`: directory for outputs.
    -  `parkinson_xai/heatmaps`: heatmaps generated by the XAI techniques.
    -  `parkinson_xai/stats`: relevance analysis results.
       -  `parkinson_xai/stats/splits`: relevance analysis results of each experiment.
       -  `parkinson_xai/stats/grouped`: summaries of the relevance analyses.
    -  `parkinson_xai/plots`: diagrams of the relevance analysis results.
        -  `parkinson_xai/plots/barplots`: bar diagrams.
        -  `parkinson_xai/plots/boxplots`: box diagrams.
        -  `parkinson_xai/plots/comparative`: comparative bar diagrams.
    -  `parkinson_xai/planes`: comparative images of the heatmaps.

### Availability of models
The user must have the input sets and pre-trained models from the original project, which must be located in the specified directories. More information on how to train the models can be found in the [repository of the original article](https://github.com/ayrna/ordinal-cnn-parkinsons).

### Adaptation of LRP
One of the explanatory methods used is **LRP**, obtained from the **Captum** library. However, some changes need to be made to the original code to make it compatible with the models used.

The project does not include the original file, which can be downloaded from the [**Captum** repository](https://github.com/pytorch/captum/blob/master/captum/attr/_core/lrp.py) on **GitHub**. Instead, the `lrp.patch` file is provided, which allows the necessary modifications to be applied to the original `lrp.py` file by running the following command:
```bash
patch lrp.py < lrp.patch
```

The user must ensure that they have an `lrp.py` file in the working directory with the modifications made after applying the patch.


## Usage
The main experiment consists of four executables.

First, apply the explanatory methods to all possible models and configurations, generating the resulting heatmaps. To do this, run the following command:
```bash
python explain_model.py  run
```

To analyze the influence assigned to the features learned by the models for decision-making, calculating the relevance of the ROIs identified in the heatmaps, use the following script:
```bash
python calculate_stats.py  --method [method] --model [model] --fold [fold]
```
where:
-  `method` indicates the explanatory method whose results will be analyzed.
-  `model` indicates the type of classifier to be analyzed.
-  `fold` indicates the fold to be analyzed. Optional, if not included, all folds are analyzed.

To facilitate the interpretation of the analyses, a script is included that generates bar and box plots, representing a ranking of the brain regions identified as most relevant during the analyses of the classification models. The execution format is as follows:
```bash
python plot_rankings.py  --method [method] --model [model] --plot_type [plot_type]
```
where:
-   `method` indicates the explanatory method whose analyses will be represented.
-   `model` indicates the CNN model to be represented.
-   `plot_type` indicates the type of diagram to be generated.
  
If you want to obtain two-dimensional comparative images of the heatmaps obtained after applying different explanatory techniques, you can run the following script:

```bash
python visualize_heatmaps.py  --model [model] --fold [fold] --split [split]
```
where:
-   `model` indicates the CNN model whose results will be represented.
-   `fold` indicates the fold of the experiment to be represented.
-   `split` indicates the split of the experiment to be represented.


## Other components
This project includes additional functionalities.

### Unit Tests
To validate the correct functionality of the class modules, a set of unit tests implemented using `pytest` is included.

To execute these scripts, navigate to the `parkinson_signac/tests` directory, where the executable files are located. Run the scripts using the following command:
```bash
pytest [name of the test file]
```

### Conversion to NifTI Images
The heatmaps generated by the `explain_model.py` script are stored with the `.pt` extension, rather than the `.nii.gz` extension used by NifTI images. This means the heatmaps lack the metadata and headers typical of this type of image.

The `convert_to_nifti.py` script has been included, which takes an input file of type `.pt`, incorporates the metadata stored in the `nifti_metadata.pkl` file, and stores the resulting NifTI image.
```bash
 python convert_to_nifti.py [input].pt [output].nii.gz
```
